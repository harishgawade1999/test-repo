{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# News Article Summarization and Keyword Extraction via NLP\n",
    "\n",
    "In this demo, we will create an NLP pipeline that will summarize and extract keywords from a news article URL. We will be using state-of-the-art transformer models such as BERT to perform these NLP tasks.\n",
    "\n",
    "Additionally, we will be using MLRun's real-time inference graphs to create the pipeline. This allows for easy containerization and deployment of our pipeline on top of a production-ready Kubernetes cluster.\n",
    "\n",
    "The full pipeline will do the following:\n",
    "1. Retrieve news article text and metadata from URL using newspaper3k\n",
    "2. Summarize article text via Huggingface pipeline using DistilBart model\n",
    "3. Extract article keywords via KeyBERT using BERT-embeddings and cosine similarity\n",
    "4. Remove the original article text from the response (optional)\n",
    "5. Persist record in KV table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Local Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers==4.11.3\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting newspaper3k==0.2.8\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keybert~=0.7.0\n",
      "  Downloading keybert-0.7.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m330.3/330.3 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests in /opt/conda/lib/python3.9/site-packages (from transformers==4.11.3) (2.28.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.9/site-packages (from transformers==4.11.3) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.9/site-packages (from transformers==4.11.3) (1.22.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.9/site-packages (from transformers==4.11.3) (5.4.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.4/773.4 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from transformers==4.11.3) (21.3)\n",
      "Collecting feedparser>=5.2.1\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tldextract>=2.0.1\n",
      "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.7/97.7 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jieba3k>=0.35.1\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0mm\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting feedfinder2>=0.0.4\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting nltk>=3.2.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /opt/conda/lib/python3.9/site-packages (from newspaper3k==0.2.8) (2.8.2)\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /opt/conda/lib/python3.9/site-packages (from newspaper3k==0.2.8) (9.2.0)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /opt/conda/lib/python3.9/site-packages (from newspaper3k==0.2.8) (4.11.1)\n",
      "Collecting cssselect>=0.9.2\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tinysegmenter==0.3\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting lxml>=3.6.0\n",
      "  Downloading lxml-5.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.0/8.0 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: scikit-learn>=0.22.2 in /opt/conda/lib/python3.9/site-packages (from keybert~=0.7.0) (1.1.2)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m240.6/240.6 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (2.3.2.post1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from feedfinder2>=0.0.4->newspaper3k==0.2.8) (1.16.0)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.0/169.0 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.4.0)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (8.0.4)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (1.2.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->transformers==4.11.3) (3.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.11.3) (1.26.11)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.11.3) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.11.3) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests->transformers==4.11.3) (2022.9.24)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from rich>=10.4.0->keybert~=0.7.0) (2.13.0)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m793.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert~=0.7.0) (3.1.0)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert~=0.7.0) (1.9.1)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
      "\u001b[?25hCollecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp39-cp39-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (1.11.1)\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:04\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: networkx in /opt/conda/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (2.8.7)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.9/site-packages (from sympy->torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (1.2.1)\n",
      "Building wheels for collected packages: tinysegmenter, keybert, feedfinder2, jieba3k, sentence-transformers, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13540 sha256=60655b1b3505125302776beb9f186cc46fecfded200a7994ecab5c469f935bf4\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/e9/bd/bc/775f8c348e77199b81c54f0eae203ec3328c3ff6678199af53\n",
      "  Building wheel for keybert (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23776 sha256=33d3d00e053b45b54f04d1db000a2d34cf5047740c79d3631d443bf621b25253\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/6b/6d/dd/a3e492c7b46f3e3864d7fb4119aa812ebc41ee2808ceb26414\n",
      "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=405b0e3603b3ca1d970bfb60f9f17a711a9d3c7dae5602013be8a137157db996\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/c4/ef/21/80dce75dfac58c5d3afbbd56093cd9aaf16aebacea63ed478e\n",
      "  Building wheel for jieba3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398381 sha256=71cc858a9f2abf4895a1a8dd58fa72e321d0827f93f0479e5015804a81f8ce15\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/7e/90/13/9595f17d4f8a6ce036a2fc15457a3d99642b2e16886f161d43\n",
      "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125925 sha256=a8e1405c09e7531b6ec97a4c735712661b8010161a94aa0d083cbe64288876d1\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/4b/68/65/aba8be86302d9988b832f5e1f3417a87e4a868d396e4329f0a\n",
      "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6048 sha256=8ae66a390d356cfe37d08b88c235b418c8d85949564b3db516ea3685dc8ffcde\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-nmxus0_3/wheels/00/a1/4a/3aaa30857be3b96a4a11fccfa1336686def7d898b8be2509dd\n",
      "Successfully built tinysegmenter keybert feedfinder2 jieba3k sentence-transformers sgmllib3k\n",
      "Installing collected packages: tokenizers, tinysegmenter, sgmllib3k, sentencepiece, jieba3k, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, mdurl, lxml, fsspec, filelock, feedparser, cssselect, triton, sacremoses, requests-file, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, huggingface-hub, feedfinder2, transformers, tldextract, rich, nvidia-cusolver-cu12, torch, newspaper3k, torchvision, sentence-transformers, keybert\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.1.0 requires fsspec==2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "mlrun 1.4.0 requires fsspec~=2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "gcsfs 2023.1.0 requires fsspec==2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.20.2 jieba3k-0.35.1 keybert-0.7.0 lxml-5.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 newspaper3k-0.2.8 nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 regex-2023.12.25 requests-file-1.5.1 rich-13.7.0 sacremoses-0.1.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sgmllib3k-1.0.0 tinysegmenter-0.3 tldextract-5.1.1 tokenizers-0.10.3 torch-2.1.2 torchvision-0.16.2 transformers-4.11.3 triton-2.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define MLRun Function\n",
    "Here we define the serverless function that will containerize and deploy our application. We can add dependencies and commands to the image build, define replicas for scaling, add environment variables, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlrun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-01-05 12:51:13,397 [info] Created and saved project: {'name': 'nlp-demo-jovyan', 'from_template': None, 'overwrite': False, 'context': './', 'save': True}\n",
      "> 2024-01-05 12:51:13,399 [info] Project created successfully: {'project_name': 'nlp-demo', 'stored_in_db': True}\n"
     ]
    }
   ],
   "source": [
    "project_name = \"nlp-demo\"\n",
    "project = mlrun.get_or_create_project(project_name, context=\"./\", user_project=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-01-05 12:51:13,406 [warning] Failed to add git metadata, ignore if path is not part of a git repo.: {'path': './', 'error': '/home/jovyan'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<mlrun.runtimes.serving.ServingRuntime at 0x7f0b3016e640>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fn = mlrun.code_to_function(name=\"news-article-nlp\", filename=\"nlp_transformations.py\",\n",
    "                            kind=\"serving\", image='mlrun/mlrun')\n",
    "fn.spec.min_replicas = 1\n",
    "fn.spec.max_replicas = 1\n",
    "fn.spec.build.commands = [\n",
    "    \"python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0\",\n",
    "    \"python -c 'from transformers import pipeline; pipeline(\\\"summarization\\\")'\",\n",
    "    \"python -c 'from keybert import KeyBERT; KeyBERT()'\"\n",
    "]\n",
    "fn.set_env(\"SENTENCE_TRANSFORMERS_HOME\",\"/tmp\")\n",
    "fn.set_env(\"TRANSFORMERS_CACHE\",\"/tmp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Real-Time Serving Graph\n",
    "Here we will orchestrate the functions and classes we want to run in our pipeline. The source code for these functions is located in `project/nlp_transformations.py`. Notice, this is the same file we used when running `code_to_function` in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "redis_url = \"redis://:@127.0.0.1:6379\"\n",
    "\n",
    "if not redis_url:\n",
    "    if os.environ.get('V3IO_ACCESS_KEY'): # Running on iguazio platform\n",
    "        container = \"bigdata\"\n",
    "        table_path = f\"nlp-{os.getenv('V3IO_USERNAME')}\"\n",
    "        key = \"title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: mlrun&#45;flow Pages: 1 -->\n",
       "<svg width=\"1019pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 1018.52 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>mlrun&#45;flow</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 1014.52,-40 1014.52,4 -4,4\"/>\n",
       "<!-- _start -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>_start</title>\n",
       "<polygon fill=\"lightgrey\" stroke=\"black\" points=\"31.43,-0.05 33.2,-0.15 34.96,-0.3 36.69,-0.49 38.39,-0.74 40.05,-1.03 41.67,-1.36 43.23,-1.75 44.73,-2.18 46.17,-2.65 47.54,-3.16 48.84,-3.71 50.06,-4.31 51.2,-4.94 52.25,-5.61 53.22,-6.31 54.09,-7.04 54.87,-7.8 55.56,-8.59 56.15,-9.41 56.65,-10.25 57.05,-11.11 57.36,-11.99 57.58,-12.89 57.7,-13.8 57.73,-14.72 57.68,-15.65 57.54,-16.59 57.31,-17.53 57.01,-18.47 56.63,-19.41 56.18,-20.35 55.66,-21.28 55.08,-22.2 54.43,-23.11 53.72,-24.01 52.97,-24.89 52.16,-25.75 51.3,-26.59 50.41,-27.41 49.48,-28.2 48.51,-28.96 47.51,-29.69 46.48,-30.39 45.43,-31.06 44.35,-31.69 43.26,-32.29 42.15,-32.84 41.02,-33.35 39.89,-33.82 38.74,-34.25 37.58,-34.64 36.42,-34.97 35.24,-35.26 34.07,-35.51 32.89,-35.7 31.71,-35.85 30.52,-35.95 29.34,-36 28.15,-36 26.96,-35.95 25.78,-35.85 24.6,-35.7 23.42,-35.51 22.24,-35.26 21.07,-34.97 19.91,-34.64 18.75,-34.25 17.6,-33.82 16.46,-33.35 15.34,-32.84 14.23,-32.29 13.13,-31.69 12.06,-31.06 11.01,-30.39 9.98,-29.69 8.98,-28.96 8.01,-28.2 7.08,-27.41 6.18,-26.59 5.33,-25.75 4.52,-24.89 3.76,-24.01 3.06,-23.11 2.41,-22.2 1.83,-21.28 1.3,-20.35 0.85,-19.41 0.47,-18.47 0.17,-17.53 -0.05,-16.59 -0.19,-15.65 -0.25,-14.72 -0.21,-13.8 -0.09,-12.89 0.13,-11.99 0.43,-11.11 0.84,-10.25 1.34,-9.41 1.93,-8.59 2.62,-7.8 3.4,-7.04 4.27,-6.31 5.24,-5.61 6.29,-4.94 7.43,-4.31 8.65,-3.71 9.94,-3.16 11.31,-2.65 12.75,-2.18 14.26,-1.75 15.82,-1.36 17.44,-1.03 19.1,-0.74 20.79,-0.49 22.53,-0.3 24.28,-0.15 26.06,-0.05 27.85,0 29.64,0 31.43,-0.05\"/>\n",
       "<text text-anchor=\"middle\" x=\"28.74\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">start</text>\n",
       "</g>\n",
       "<!-- fetch_article -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>fetch_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"148.08\" cy=\"-18\" rx=\"54.69\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"148.08\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">fetch_article</text>\n",
       "</g>\n",
       "<!-- _start&#45;&gt;fetch_article -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>_start&#45;&gt;fetch_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M57.25,-18C65.21,-18 74.25,-18 83.45,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"83.46,-21.5 93.46,-18 83.46,-14.5 83.46,-21.5\"/>\n",
       "</g>\n",
       "<!-- summarize_article -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>summarize_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"315.37\" cy=\"-18\" rx=\"76.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"315.37\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">summarize_article</text>\n",
       "</g>\n",
       "<!-- fetch_article&#45;&gt;summarize_article -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>fetch_article&#45;&gt;summarize_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M202.75,-18C210.94,-18 219.58,-18 228.26,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"228.46,-21.5 238.46,-18 228.46,-14.5 228.46,-21.5\"/>\n",
       "</g>\n",
       "<!-- extract_keywords -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>extract_keywords</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"501.51\" cy=\"-18\" rx=\"73.39\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"501.51\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">extract_keywords</text>\n",
       "</g>\n",
       "<!-- summarize_article&#45;&gt;extract_keywords -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>summarize_article&#45;&gt;extract_keywords</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M392.33,-18C400.71,-18 409.28,-18 417.73,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"417.98,-21.5 427.98,-18 417.98,-14.5 417.98,-21.5\"/>\n",
       "</g>\n",
       "<!-- filter_article -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>filter_article</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"664.9\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"664.9\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">filter_article</text>\n",
       "</g>\n",
       "<!-- extract_keywords&#45;&gt;filter_article -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>extract_keywords&#45;&gt;filter_article</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M575.18,-18C583.53,-18 592,-18 600.22,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"600.48,-21.5 610.48,-18 600.48,-14.5 600.48,-21.5\"/>\n",
       "</g>\n",
       "<!-- kv_format -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>kv_format</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"802.94\" cy=\"-18\" rx=\"48.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"802.94\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">kv_format</text>\n",
       "</g>\n",
       "<!-- filter_article&#45;&gt;kv_format -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>filter_article&#45;&gt;kv_format</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M718.88,-18C727.26,-18 735.96,-18 744.44,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"744.63,-21.5 754.63,-18 744.63,-14.5 744.63,-21.5\"/>\n",
       "</g>\n",
       "<!-- write_to_redis -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>write_to_redis</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"948.78\" cy=\"-18\" rx=\"61.99\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"948.78\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">write_to_redis</text>\n",
       "</g>\n",
       "<!-- kv_format&#45;&gt;write_to_redis -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>kv_format&#45;&gt;write_to_redis</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M851.04,-18C859.28,-18 868.02,-18 876.74,-18\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"876.95,-21.5 886.95,-18 876.95,-14.5 876.95,-21.5\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.graphs.Digraph at 0x7f0a7a1362b0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = fn.set_topology(\"flow\", engine=\"async\")\n",
    "\n",
    "graph.to(name=\"fetch_article\", handler=\"fetch_article\")\\\n",
    "     .to(name=\"summarize_article\", class_name=\"SummarizeArticle\")\\\n",
    "     .to(name=\"extract_keywords\", class_name=\"ExtractKeywords\")\\\n",
    "     .to(name=\"filter_article\", handler=\"filter_article\")\\\n",
    "     .to(name=\"kv_format\", handler=\"kv_format\", full_event=True)\n",
    "\n",
    "# On Iguazio's setup, V3IO fuse is enabled and using storey's steps we can write data to a KV table.\n",
    "# when using community-edition, Redis service has to be deployed, and using mlrun's redisnosql target\n",
    "# create a custom additional writing step.\n",
    "\n",
    "if redis_url: # writing to redis\n",
    "    graph.add_step(name='write_to_redis',class_name=\"storey.NoSqlTarget\", table=redis_url, after='kv_format')\n",
    "\n",
    "elif os.environ.get('V3IO_ACCESS_KEY'):\n",
    "        graph.add_step(name=\"write_to_kv\", class_name=\"storey.NoSqlTarget\", table=f\"v3io:///{container}/{table_path}\", after='kv_format').respond()\n",
    "else:\n",
    "    print(\"skip writing\")\n",
    "\n",
    "graph.plot(rankdir='LR')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the Pipeline Locally (using simulator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to sshleifer/distilbart-cnn-12-6 (https://huggingface.co/sshleifer/distilbart-cnn-12-6)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "844e5ca1e24d46e59427e82c79660088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.76k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a33f7335590489fa36b6084f07439e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.14G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e7f873cc2443babbafa947a55fa36e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e54f6f380b324b9e85904d8c634b97f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeeac0dda03b4dc8af816b97254842ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d9522bbcb5843c3b0eafed95d1a291d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes:   0%|          | 0.00/1.18k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f64d266e7c045868bbff950df90d75c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bb4f2f73c1d4641985a9e18f19664e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3da5d693c45a48baaf457e51e5624f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b075f50c37e46d6808e4b16dd34af43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2df4e2a8eedd402890f705d630fd5e22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data_config.json:   0%|          | 0.00/39.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "324bc617a6d4478ea5758be8021ea5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d0fd0a4e74c4f5691f09a1b33d647f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d728c437b1a244598666e08b2e883d0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b83a0c5426f045cdb6e022562b9a34dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "734824d7edac4f0c868a7b555f53fa07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "921116090dcd4afab85fae82f5a61502",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train_script.py:   0%|          | 0.00/13.2k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0af7dd6a06464536b14473635ca39552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb830406bd8d467b92e114bfaefc68d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import the step functions for simulation\n",
    "from nlp_transformations import *\n",
    "\n",
    "# create a mock server (simulator)\n",
    "server = fn.to_mock_server()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '177082db9fbe40c88d966376ff6a678e'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test the pipeline\n",
    "server.test(\"/\", body={\"url\" : \"https://edition.cnn.com/2022/10/23/motorsport/dietrich-mateschitz-tributes-red-bull-spt-intl/index.html\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Containerize and Deploy Pipeline on K8s\n",
    "Here we easily containerize and deploy our application to our K8s cluster with a single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> 2024-01-05 12:55:14,016 [warning] it is recommended to use k8s secret (specify secret_name), specifying the aws_access_key/aws_secret_key directly is unsafe\n",
      "> 2024-01-05 12:55:14,021 [info] Starting remote function deploy\n",
      "2024-01-05 12:55:14  (info) Deploying function\n",
      "2024-01-05 12:55:14  (info) Building\n",
      "2024-01-05 12:55:14  (info) Staging files and preparing base images\n",
      "2024-01-05 12:55:14  (info) Building processor image\n",
      "2024-01-05 13:07:57  (warn) Function creation failed, updating function status\n",
      "Failed to deploy. Details:\n",
      "\n",
      "Error - Job failed. Job logs:\n",
      "INFO[0002] Resolved base name quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 to python-onbuild \n",
      "INFO[0002] Retrieving image manifest quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 \n",
      "INFO[0002] Retrieving image quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 from registry quay.io \n",
      "INFO[0004] Retrieving image manifest quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 \n",
      "INFO[0004] Returning cached image manifest              \n",
      "INFO[0006] Retrieving image manifest mlrun/mlrun:1.4.0  \n",
      "INFO[0006] Retrieving image mlrun/mlrun:1.4.0 from registry index.docker.io \n",
      "INFO[0008] Retrieving image manifest mlrun/mlrun:1.4.0  \n",
      "INFO[0008] Returning cached image manifest              \n",
      "INFO[0008] Built cross stage deps: map[0:[/home/nuclio/bin/processor /home/nuclio/bin/py /home/nuclio/bin/py3.9-whl]] \n",
      "INFO[0008] Retrieving image manifest quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 \n",
      "INFO[0008] Returning cached image manifest              \n",
      "INFO[0008] Retrieving image manifest quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64 \n",
      "INFO[0008] Returning cached image manifest              \n",
      "INFO[0008] Executing 0 build triggers                   \n",
      "INFO[0008] Building stage 'quay.io/nuclio/handler-builder-python-onbuild:1.11.23-amd64' [idx: '0', base-idx: '-1'] \n",
      "INFO[0022] ARG NUCLIO_LABEL                             \n",
      "INFO[0022] No files changed in this command, skipping snapshotting. \n",
      "INFO[0022] ARG NUCLIO_ARCH                              \n",
      "INFO[0022] No files changed in this command, skipping snapshotting. \n",
      "INFO[0022] Saving file home/nuclio/bin/processor for later use \n",
      "INFO[0022] Saving file home/nuclio/bin/py for later use \n",
      "INFO[0022] Saving file home/nuclio/bin/py3.9-whl for later use \n",
      "INFO[0022] Deleting filesystem...                       \n",
      "INFO[0022] Retrieving image manifest mlrun/mlrun:1.4.0  \n",
      "INFO[0022] Returning cached image manifest              \n",
      "INFO[0022] Retrieving image manifest mlrun/mlrun:1.4.0  \n",
      "INFO[0022] Returning cached image manifest              \n",
      "INFO[0022] Executing 0 build triggers                   \n",
      "INFO[0022] Building stage 'mlrun/mlrun:1.4.0' [idx: '1', base-idx: '-1'] \n",
      "INFO[0022] Checking for cached layer registry.hub.docker.com/harishgawade199/processor-nlp-demo-jovyan-news-article-nlp/cache:18b7a0e81a8090c9d91b50af32036febf2191ef12e9120fe68280b992f8033c6... \n",
      "INFO[0024] No cached layer found for cmd RUN python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0 \n",
      "INFO[0024] Unpacking rootfs as cmd RUN python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0 requires it. \n",
      "INFO[0105] ARG NUCLIO_LABEL                             \n",
      "INFO[0105] No files changed in this command, skipping snapshotting. \n",
      "INFO[0105] ARG NUCLIO_ARCH                              \n",
      "INFO[0105] No files changed in this command, skipping snapshotting. \n",
      "INFO[0105] ARG NUCLIO_BUILD_LOCAL_HANDLER_DIR           \n",
      "INFO[0105] No files changed in this command, skipping snapshotting. \n",
      "INFO[0105] RUN python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0 \n",
      "INFO[0105] Initializing snapshotter ...                 \n",
      "INFO[0105] Taking snapshot of full filesystem...        \n",
      "INFO[0124] Cmd: /bin/sh                                 \n",
      "INFO[0124] Args: [-c python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0] \n",
      "INFO[0124] Running: [/bin/sh -c python -m pip install transformers==4.11.3 newspaper3k==0.2.8 keybert~=0.7.0] \n",
      "Collecting transformers==4.11.3\n",
      "  Downloading transformers-4.11.3-py3-none-any.whl (2.9 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.9/2.9 MB 7.4 MB/s eta 0:00:00\n",
      "Collecting newspaper3k==0.2.8\n",
      "  Downloading newspaper3k-0.2.8-py3-none-any.whl (211 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 211.1/211.1 kB 8.3 MB/s eta 0:00:00\n",
      "Collecting keybert~=0.7.0\n",
      "  Downloading keybert-0.7.0.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "  Downloading tokenizers-0.10.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 3.3/3.3 MB 7.2 MB/s eta 0:00:00\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/site-packages (from transformers==4.11.3) (23.1)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2023.12.25-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 773.4/773.4 kB 9.9 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/site-packages (from transformers==4.11.3) (2.31.0)\n",
      "Collecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.1-py3-none-any.whl (78 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 78.3/78.3 kB 12.5 MB/s eta 0:00:00\n",
      "Collecting huggingface-hub>=0.0.17\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 330.3/330.3 kB 11.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/site-packages (from transformers==4.11.3) (5.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/site-packages (from transformers==4.11.3) (1.22.4)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.1.1-py3-none-any.whl (897 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 897.5/897.5 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting feedfinder2>=0.0.4\n",
      "  Downloading feedfinder2-0.0.4.tar.gz (3.3 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting lxml>=3.6.0\n",
      "  Downloading lxml-5.0.0-cp39-cp39-manylinux_2_28_x86_64.whl (8.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 8.0/8.0 MB 6.9 MB/s eta 0:00:00\n",
      "Collecting tinysegmenter==0.3\n",
      "  Downloading tinysegmenter-0.3.tar.gz (16 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting feedparser>=5.2.1\n",
      "  Downloading feedparser-6.0.11-py3-none-any.whl (81 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 81.3/81.3 kB 687.1 kB/s eta 0:00:00\n",
      "Collecting cssselect>=0.9.2\n",
      "  Downloading cssselect-1.2.0-py2.py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.9/site-packages (from newspaper3k==0.2.8) (2.8.2)\n",
      "Requirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.9/site-packages (from newspaper3k==0.2.8) (4.12.2)\n",
      "Collecting tldextract>=2.0.1\n",
      "  Downloading tldextract-5.1.1-py3-none-any.whl (97 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 97.7/97.7 kB 840.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.9/site-packages (from newspaper3k==0.2.8) (10.0.0)\n",
      "Collecting nltk>=3.2.1\n",
      "  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 9.7 MB/s eta 0:00:00\n",
      "Collecting jieba3k>=0.35.1\n",
      "  Downloading jieba3k-0.35.1.zip (7.4 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 7.4/7.4 MB 6.9 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting sentence-transformers>=0.3.8\n",
      "  Downloading sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 86.0/86.0 kB 22.5 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in /usr/local/lib/python3.9/site-packages (from keybert~=0.7.0) (1.3.0)\n",
      "Collecting rich>=10.4.0\n",
      "  Downloading rich-13.7.0-py3-none-any.whl (240 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 240.6/240.6 kB 11.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/site-packages (from beautifulsoup4>=4.4.1->newspaper3k==0.2.8) (2.4.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.9/site-packages (from feedfinder2>=0.0.4->newspaper3k==0.2.8) (1.16.0)\n",
      "Collecting sgmllib3k\n",
      "  Downloading sgmllib3k-1.0.0.tar.gz (5.8 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/site-packages (from huggingface-hub>=0.0.17->transformers==4.11.3) (4.7.1)\n",
      "Collecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2023.12.2-py3-none-any.whl (168 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 169.0/169.0 kB 11.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (1.3.1)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.9/site-packages (from nltk>=3.2.1->newspaper3k==0.2.8) (8.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.11.3) (1.26.16)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.11.3) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.11.3) (2023.5.7)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/site-packages (from requests->transformers==4.11.3) (3.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/site-packages (from rich>=10.4.0->keybert~=0.7.0) (2.15.1)\n",
      "Collecting markdown-it-py>=2.2.0\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 87.5/87.5 kB 11.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert~=0.7.0) (1.11.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/site-packages (from scikit-learn>=0.22.2->keybert~=0.7.0) (3.2.0)\n",
      "Collecting torch>=1.6.0\n",
      "  Downloading torch-2.1.2-cp39-cp39-manylinux1_x86_64.whl (670.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 670.2/670.2 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.16.2-cp39-cp39-manylinux1_x86_64.whl (6.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.8/6.8 MB 6.3 MB/s eta 0:00:00\n",
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.99-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 10.4 MB/s eta 0:00:00\n",
      "Collecting requests-file>=1.4\n",
      "  Downloading requests_file-1.5.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Collecting mdurl~=0.1\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Collecting nvidia-cusparse-cu12==12.1.0.106\n",
      "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 196.0/196.0 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-nccl-cu12==2.18.1\n",
      "  Downloading nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 209.8/209.8 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cusolver-cu12==11.4.5.107\n",
      "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 124.2/124.2 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting triton==2.1.0\n",
      "  Downloading triton-2.1.0-0-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.3 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 89.3/89.3 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting networkx\n",
      "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.6/1.6 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-runtime-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 823.6/823.6 kB 11.3 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvtx-cu12==12.1.105\n",
      "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 99.1/99.1 kB 888.8 kB/s eta 0:00:00\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/site-packages (from torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (3.1.2)\n",
      "Collecting nvidia-cufft-cu12==11.0.2.54\n",
      "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 121.6/121.6 MB 5.8 MB/s eta 0:00:00\n",
      "Collecting nvidia-cublas-cu12==12.1.3.1\n",
      "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 410.6/410.6 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting sympy\n",
      "  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.7/5.7 MB 7.1 MB/s eta 0:00:00\n",
      "Collecting nvidia-curand-cu12==10.3.2.106\n",
      "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 56.5/56.5 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-cupti-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 14.1/14.1 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.1.105\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 23.7/23.7 MB 5.9 MB/s eta 0:00:00\n",
      "Collecting nvidia-cudnn-cu12==8.9.2.26\n",
      "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 731.7/731.7 MB 6.0 MB/s eta 0:00:00\n",
      "Collecting nvidia-nvjitlink-cu12\n",
      "  Downloading nvidia_nvjitlink_cu12-12.3.101-py3-none-manylinux1_x86_64.whl (20.5 MB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 20.5/20.5 MB 5.8 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/site-packages (from jinja2->torch>=1.6.0->sentence-transformers>=0.3.8->keybert~=0.7.0) (2.1.3)\n",
      "Collecting mpmath>=0.19\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 536.2/536.2 kB 3.3 MB/s eta 0:00:00\n",
      "Building wheels for collected packages: tinysegmenter, keybert, feedfinder2, jieba3k, sentence-transformers, sgmllib3k\n",
      "  Building wheel for tinysegmenter (setup.py): started\n",
      "  Building wheel for tinysegmenter (setup.py): finished with status 'done'\n",
      "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-py3-none-any.whl size=13541 sha256=f15d37b2841c47d9cbd3992d41c14debfd2819c38a8e83a7e3cebd05d44166fc\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/e9/bd/bc/775f8c348e77199b81c54f0eae203ec3328c3ff6678199af53\n",
      "  Building wheel for keybert (setup.py): started\n",
      "  Building wheel for keybert (setup.py): finished with status 'done'\n",
      "  Created wheel for keybert: filename=keybert-0.7.0-py3-none-any.whl size=23777 sha256=7e902ad2b9dcfbc7c377b8fa7a40725caaf2a6e48ae61793ee310a001d64fe53\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/6b/6d/dd/a3e492c7b46f3e3864d7fb4119aa812ebc41ee2808ceb26414\n",
      "  Building wheel for feedfinder2 (setup.py): started\n",
      "  Building wheel for feedfinder2 (setup.py): finished with status 'done'\n",
      "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-py3-none-any.whl size=3341 sha256=184ac76f5f0d1d0e35d2ba7fd921ed427e422c69f0e6bf5720d716290dc31ab5\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/c4/ef/21/80dce75dfac58c5d3afbbd56093cd9aaf16aebacea63ed478e\n",
      "  Building wheel for jieba3k (setup.py): started\n",
      "  Building wheel for jieba3k (setup.py): finished with status 'done'\n",
      "  Created wheel for jieba3k: filename=jieba3k-0.35.1-py3-none-any.whl size=7398382 sha256=0b51bc149438c7db440da6f1467a027064865e5d47d798444f37802528f09327\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/7e/90/13/9595f17d4f8a6ce036a2fc15457a3d99642b2e16886f161d43\n",
      "  Building wheel for sentence-transformers (setup.py): started\n",
      "  Building wheel for sentence-transformers (setup.py): finished with status 'done'\n",
      "  Created wheel for sentence-transformers: filename=sentence_transformers-2.2.2-py3-none-any.whl size=125926 sha256=afa7dc97fcd85cbdea3dfe2db2d4ccc83ba2ec5ad346c57a1cd8d0ea3b4625ca\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/4b/68/65/aba8be86302d9988b832f5e1f3417a87e4a868d396e4329f0a\n",
      "  Building wheel for sgmllib3k (setup.py): started\n",
      "  Building wheel for sgmllib3k (setup.py): finished with status 'done'\n",
      "  Created wheel for sgmllib3k: filename=sgmllib3k-1.0.0-py3-none-any.whl size=6046 sha256=1a473e26ee856041abe5382a112bcc41a5fde915761738a7d80e65f6ec8c63db\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-pkwej7ry/wheels/00/a1/4a/3aaa30857be3b96a4a11fccfa1336686def7d898b8be2509dd\n",
      "Successfully built tinysegmenter keybert feedfinder2 jieba3k sentence-transformers sgmllib3k\n",
      "Installing collected packages: tokenizers, tinysegmenter, sgmllib3k, sentencepiece, mpmath, jieba3k, tqdm, sympy, regex, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, networkx, mdurl, lxml, fsspec, filelock, feedparser, cssselect, triton, sacremoses, requests-file, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nltk, markdown-it-py, huggingface-hub, feedfinder2, transformers, tldextract, rich, nvidia-cusolver-cu12, torch, newspaper3k, torchvision, sentence-transformers, keybert\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2023.1.0\n",
      "    Uninstalling fsspec-2023.1.0:\n",
      "      Successfully uninstalled fsspec-2023.1.0\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "s3fs 2023.1.0 requires fsspec==2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "mlrun 1.4.0 requires fsspec~=2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "gcsfs 2023.1.0 requires fsspec==2023.1.0, but you have fsspec 2023.12.2 which is incompatible.\n",
      "WARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\n",
      "Successfully installed cssselect-1.2.0 feedfinder2-0.0.4 feedparser-6.0.11 filelock-3.13.1 fsspec-2023.12.2 huggingface-hub-0.20.2 jieba3k-0.35.1 keybert-0.7.0 lxml-5.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mpmath-1.3.0 networkx-3.2.1 newspaper3k-0.2.8 nltk-3.8.1 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvjitlink-cu12-12.3.101 nvidia-nvtx-cu12-12.1.105 regex-2023.12.25 requests-file-1.5.1 rich-13.7.0 sacremoses-0.1.1 sentence-transformers-2.2.2 sentencepiece-0.1.99 sgmllib3k-1.0.0 sympy-1.12 tinysegmenter-0.3 tldextract-5.1.1 tokenizers-0.10.3 torch-2.1.2 torchvision-0.16.2 tqdm-4.66.1 transformers-4.11.3 triton-2.1.0\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.3.2\n",
      "[notice] To update, run: pip install --upgrade pip\n",
      "INFO[0612] Taking snapshot of full filesystem...        \n",
      "    /nuclio/pkg/processor/build/builder.go:264\n",
      "\n",
      "Call stack:\n",
      "Failed to build processor image\n",
      "    /nuclio/pkg/processor/build/builder.go:264\n",
      "\n",
      "> 2024-01-05 13:08:07,952 [error] Nuclio function failed to deploy: {'function_state': 'error'}\n"
     ]
    },
    {
     "ename": "RunError",
     "evalue": "function news-article-nlp deployment failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRunError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [9], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m fn\u001b[38;5;241m.\u001b[39mspec\u001b[38;5;241m.\u001b[39mreadinessTimeoutSeconds \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m60\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m  \u001b[38;5;66;03m# 30 minutes.\\n\",\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mfn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/serving.py:637\u001b[0m, in \u001b[0;36mServingRuntime.deploy\u001b[0;34m(self, dashboard, project, tag, verbose, auth_info, builder_env)\u001b[0m\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deploy_function_refs()\n\u001b[1;32m    635\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeploy root function \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 637\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdeploy\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdashboard\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproject\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth_info\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuilder_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbuilder_env\u001b[49m\n\u001b[1;32m    639\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/function.py:587\u001b[0m, in \u001b[0;36mRemoteRuntime.deploy\u001b[0;34m(self, dashboard, project, tag, verbose, auth_info, builder_env)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_credentials_from_remote_build(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    585\u001b[0m \u001b[38;5;66;03m# when a function is deployed, we wait for it to be ready by default\u001b[39;00m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# this also means that the function object will be updated with the function status\u001b[39;00m\n\u001b[0;32m--> 587\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wait_for_function_deployment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;66;03m# NOTE: on older mlrun versions & nuclio versions, function are exposed via NodePort\u001b[39;00m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;66;03m#       now, functions can be not exposed (using service type ClusterIP) and hence\u001b[39;00m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;66;03m#       for BC we first try to populate the external invocation url, and then\u001b[39;00m\n\u001b[1;32m    592\u001b[0m \u001b[38;5;66;03m#       if not exists, take the internal invocation url\u001b[39;00m\n\u001b[1;32m    593\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus\u001b[38;5;241m.\u001b[39mexternal_invocation_urls:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.9/site-packages/mlrun/runtimes/function.py:634\u001b[0m, in \u001b[0;36mRemoteRuntime._wait_for_function_deployment\u001b[0;34m(self, db, verbose)\u001b[0m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mready\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    633\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNuclio function failed to deploy\u001b[39m\u001b[38;5;124m\"\u001b[39m, function_state\u001b[38;5;241m=\u001b[39mstate)\n\u001b[0;32m--> 634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m RunError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfunction \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmetadata\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m deployment failed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mRunError\u001b[0m: function news-article-nlp deployment failed"
     ]
    }
   ],
   "source": [
    "fn.spec.readinessTimeoutSeconds = 60 * 30  # 30 minutes.\\n\",\n",
    "fn.deploy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Pipeline with URLs From Various News Sources \n",
    "Here we can test the pipeline with various news sources. This pipeline should work with any source compatible with the `newspaper3k` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://edition.cnn.com/2022/10/22/china/china-party-congress-overseas-students-protest-intl-hnk/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://edition.cnn.com/2022/10/23/entertainment/matthew-perry-jennifer-aniston-alcohol/index.html\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://www.npr.org/2022/10/24/1130915534/the-houston-astros-and-philadelphia-phillies-will-face-each-other-in-the-world-s\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fn.invoke(\n",
    "    path=\"/\",\n",
    "    body={\"url\" : \"https://abcnews.go.com/Politics/jan-committee-trumps-testimony-circus-cheney/story?id=91963586\",\n",
    "          \"filter_article\" : False}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define KV Table Schema for Dashboard\n",
    "While a schema is not required to write records to a table, it is required for the table to be displayed in a Grafana dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get('V3IO_ACCESS_KEY') :\n",
    "\n",
    "    print (\"creating key value schema\")\n",
    "\n",
    "    import v3io.dataplane\n",
    "\n",
    "    v3io_client = v3io.dataplane.Client()\n",
    "\n",
    "    v3io_client.kv.create_schema(\n",
    "        container=container,\n",
    "        table_path=table_path,\n",
    "        key=key,\n",
    "        fields = [\n",
    "            {'name': 'url',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'filter_article',\n",
    "             'type': 'boolean',\n",
    "             'nullable': False},\n",
    "            {'name': 'title',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'authors',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'publish_date',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'original_text',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'summarized_text',\n",
    "             'type': 'string',\n",
    "             'nullable': False},\n",
    "            {'name': 'keywords',\n",
    "             'type': 'string',\n",
    "             'nullable': False}\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View Dashboard"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "After using the pipeline, we will be able to visualize the article summary, keywords, and metadata in a Grafana dashboard. The JSON file for the dashboard is available under `grafana_dashboard.json`.\n",
    "\n",
    "After importing into Grafana and running the pipeline above, the dashboard will look something like the following:\n",
    "![](./dashboard_preview.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
